{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfUt7BmNzkIx"
   },
   "source": [
    "# Project 1: First steps in Machine Learning (70 Points)\n",
    "In this project, you will train and evaluate your first machine learning models. We provide a structure with a lot of **TODO**s guiding you through the work. Please read the following information carefully.\n",
    "\n",
    "## Grading\n",
    "You can gain a total of 70 points in this project.\n",
    "\n",
    "Please follow the **TODO**s in this notebook. There are practical and theoretical tasks to do.<br>\n",
    "When working on the tasks please consider the following information:\n",
    "* write short texts in **full sentences** answering the TODOs. Note, that analyzing the theoratical parts of the project give roughly 2/3 of all points (at least in part 1)\n",
    "* when describing classifiers explain at least the training, testing, and the hyper-parameters\n",
    "* have a look at all imports in this notebook; they already define which method you should use\n",
    "\n",
    "\n",
    "## Organizational and Deadline\n",
    "On Monday, **November 13th**, there will be a Q&A session in the tutorials! Start to work on this project **from now on** and take the offer to resolve any remaining ambiguity.\n",
    "This assignment is due on **November 21st**. Please upload your solution to the Lernraum+ as an ipynb-file.<br>\n",
    "For a submission you need to be part of a assignment group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCypy1U8zkI0"
   },
   "source": [
    "# Part 1: Training your first models (45 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "197KcJbGzkI3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# load dataset_1.npz\n",
    "# the data and labels are saved in X and y, respectively\n",
    "data_set = np.load('dataset_1.npz')\n",
    "X = data_set['X']\n",
    "y = data_set['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "Pp0Fida7zkJA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.90736588 -10.4482336 ]\n",
      " [  4.18121386  -3.32887987]\n",
      " [  9.70396533  -8.0533609 ]\n",
      " ...\n",
      " [ -6.57325233  -5.42912803]\n",
      " [  9.66376838   9.74861342]\n",
      " [ 11.26883707  -0.29310154]]\n",
      "[0 1 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# TODO: take a closer look at the dataset, e.g. number of samples, dimensionality, labels, etc.\n",
    "np.set_printoptions(threshold=3)\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a preview of the first and last three rows of our dataset, we investigate more on the range of values taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value of the first column -2.9073658772060376\n",
      "Maximum value of the second column 4.181213856657458\n",
      "Minimum value of the first column -10.448233596901602\n",
      "Minimum value of the second column -3.3288798667319672\n"
     ]
    }
   ],
   "source": [
    "print(f'Maximum value of the first column {np.max(X[0])}')\n",
    "print(f'Maximum value of the second column {np.max(X[1])}')\n",
    "\n",
    "print(f'Minimum value of the first column {np.min(X[0])}')\n",
    "print(f'Minimum value of the second column {np.min(X[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 800\n",
      "Dimensionality of the data: 2\n",
      "There are 2 unique labels in the dataset: [0 1]\n",
      "Count of label 0: 400\n",
      "Count of label 1: 400\n"
     ]
    }
   ],
   "source": [
    "# Number of samples\n",
    "num_samples = X.shape[0]\n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "\n",
    "# Dimensionality of the data\n",
    "dim = X.shape[1]\n",
    "print(f\"Dimensionality of the data: {dim}\")\n",
    "\n",
    "# Unique labels in the dataset\n",
    "unique_labels = np.unique(y)\n",
    "num_labels = len(unique_labels)\n",
    "print(f\"There are {num_labels} unique labels in the dataset: {unique_labels}\")\n",
    "\n",
    "# Count of each label (bincount counts the number of occurrencies for each value in an array)\n",
    "label_counts = np.bincount(y)\n",
    "# Print the count of each label (enumerate returns a tuple with the index and the value of the array)))\n",
    "for label, count in enumerate(label_counts):\n",
    "    print(f\"Count of label {label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dealing with a dataset of $800$ samples. The independent variables are $X_1$ and $X_2$ which are variables that take values in $[-10.45,-2.90]$ for $X_1$ and $[-3.33,4.18]$ for $X_2$. The dependent variable is $y$ that only takes values in $\\{0,\\;1\\}$, we have half samples labelled with $0$ and the other half labelled with $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of NaNs in the dataset is 0 for X1, 0 for X2, 0 for y\n"
     ]
    }
   ],
   "source": [
    "num_nan_x0 = np.isnan(X[0]).sum()\n",
    "num_nan_x1 = np.isnan(X[1]).sum()\n",
    "num_nan_y = np.isnan(y).sum()\n",
    "\n",
    "print(f\"The number of NaNs in the dataset is {num_nan_x0} for X1, {num_nan_x1} for X2, {num_nan_y} for y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have no NaNs in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "\n",
    "For Part 1 of the exercise, use this data split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(0.7*X.shape[0])\n",
    "n_test_val = int(0.15*X.shape[0])\n",
    "X_train = X[:n_train]\n",
    "y_train = y[:n_train]\n",
    "X_test = X[n_train:n_train+n_test_val]\n",
    "y_test = y[n_train:n_train+n_test_val]\n",
    "X_val = X[n_train+n_test_val:]\n",
    "y_val = y[n_train+n_test_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-G-3Qj8zkJH"
   },
   "source": [
    "## 1a) kNN - Classifier\n",
    "\n",
    "### the Model\n",
    "\n",
    "**TODO:** Describe the kNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN classifier is a non-parametric method. \n",
    "\n",
    "Given the dataset $\\mathcal{D}=\\{(\\vec{x}_i,y_i)\\in\\mathbb{R}^D\\times\\{1,\\;.\\;.\\;.,\\;C)\\}$, for a fixed $k\\in\\mathbb{N}_{>0}$, the idea of kNN is to estimate $\\mathbb{P}(y=j|X=x_0)$ by creating a set of points close to $x_0$ to classifie the test observation $x_0$ to the class with the largest probability.\n",
    "\n",
    "The accuracy of the classifier is defined as the percentage of ppoints which are classified correctly, i.e. $$accuracy(f,\\mathcal{D})=\\frac{|\\{\\vec{x}_i|(\\vec{X}_i,y_i)\\in\\mathcal{D},f(\\vec{x]_i)=y_i})|}{|\\mathcal{D}|}$$\n",
    "\n",
    "where for $\\mathcal{D}$ we can use the training set/ test set/ validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yoR7mM5o81n-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Annali\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\__init__.py:169: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Annali\\Desktop\\UniversitÃ \\Magistrale\\Bielefeld\\Introduction to machine learning\\Project 1\\inx\\Project1.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Annali/Desktop/Universit%C3%A0/Magistrale/Bielefeld/Introduction%20to%20machine%20learning/Project%201/inx/Project1.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m knn \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Annali/Desktop/Universit%C3%A0/Magistrale/Bielefeld/Introduction%20to%20machine%20learning/Project%201/inx/Project1.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Train the classifier\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Annali/Desktop/Universit%C3%A0/Magistrale/Bielefeld/Introduction%20to%20machine%20learning/Project%201/inx/Project1.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m knn\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Annali/Desktop/Universit%C3%A0/Magistrale/Bielefeld/Introduction%20to%20machine%20learning/Project%201/inx/Project1.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Predict the labels of the train set\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Annali/Desktop/Universit%C3%A0/Magistrale/Bielefeld/Introduction%20to%20machine%20learning/Project%201/inx/Project1.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y_train_pred \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39mpredict(X_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Train and evaluate a kNN classifier with k=3 and report the accuracy of the model on the train, validation and test set.\n",
    "#       Use the data as splitted above.\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "# Create a kNN classifier object\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the train set\n",
    "y_train_pred = knn.predict(X_train)\n",
    "\n",
    "# Predict the labels of the validation set\n",
    "y_val_pred = knn.predict(X_val)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy on the train set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Train accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Calculate and print the accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Calculate and print the accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is very high for every set of samples, syntom that the model predicts good the dependent variable. As we expected the accuracy of the train set is the higher one, because the model had been trained on that specific part of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "FY4-FS3LzkJI"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with optimal k = 6: 93.33%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train and test the kNN classifier for different values of k on dataset 1.\n",
    "#       Use the train set to train the classifier and the validation set to evaluate the performance.\n",
    "#       Plot the validation accuracy for different values of k. Choose all possible values for k.\n",
    "#       Finally train the kNN classifier with the optimal k and report the accuracy on the test set.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Initialize the list of accuracies\n",
    "accuracies = []\n",
    "\n",
    "# Loop over all possible values of k\n",
    "for k in range(1, X_train.shape[0]+1):\n",
    "    # Create a kNN classifier object\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Train the classifier\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels of the validation set\n",
    "    y_val_pred = knn.predict(X_val)\n",
    "\n",
    "    # Calculate the accuracy on the validation set and append it to the list of accuracies\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    accuracies.append(val_accuracy)\n",
    "\n",
    "# Plot the validation accuracy for different values of k\n",
    "plt.plot(range(1, len(accuracies)+1), accuracies)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Find the optimal k (the one that gives the highest validation accuracy)\n",
    "optimal_k = np.argmax(accuracies) + 1\n",
    "\n",
    "# Train the kNN classifier with the optimal k\n",
    "knn_optimal = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "knn_optimal.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_test_pred_optimal = knn_optimal.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy on the test set\n",
    "test_accuracy_optimal = accuracy_score(y_test, y_test_pred_optimal)\n",
    "print(f\"Test accuracy with optimal k = {optimal_k}: {test_accuracy_optimal*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plotted the accuracy on the validation set depending on $k$ number of neighbours taken into account during the training. As we can see we reach a high accuracy until $k = 100$ and then it starts decreasing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoj8y_WWzkJQ"
   },
   "source": [
    "**TODO:** Answer the following questions in a **full text**.\n",
    "\n",
    "* Describe your choice of values of k. Why did you choose them?\n",
    "> \n",
    "* For which values of k does the model perform best?\n",
    "> \n",
    "* Would this value perform best on another dataset as well?\n",
    "> \n",
    "* What is the smallest and the greatest possible value for k? What would happen if we would choose these special values?\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxex3z5tzkJR"
   },
   "source": [
    "## 1b) Logistic Regression\n",
    "Let's try another model as well. We will use the same dataset and split as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dygg6SnkzkJX"
   },
   "source": [
    "### the Model\n",
    "\n",
    "**TODO:** Describe the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "_nBBLXJMBSqI"
   },
   "outputs": [],
   "source": [
    "# TODO: * Train and test logistic regression on the same split of dataset_1.npz (report accuracy for train, test and validation)\n",
    "#       * Plot the dataset and the decision boundary, own implementation needed (see lecture slide 52 in slides1.pdf)\n",
    "#         where the decision boundary is optimized on the complete dataset (X).\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** How does Logistic Regression perform on this dataset? How does this relate to the properties of the model and the dataset? Answer in full sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: To achieve better performance, we apply polynomial preprocessing before fitting logistic regression. Therefor, you may construct a pipeline as shown below.\n",
    "#       Similar to kNN, optimize the polynomial degree and plot performance for different values. Pass only one degree to PolynomialFeatures (not a tuple (min,max)) at each time\n",
    "#       and validate the whole pipeline!\n",
    "#       Remember to use the train set for training and the validation set to determine the optimal polynomial degree.\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "estimators = [('poly', PolynomialFeatures(degree=1)), ('clf', LogisticRegression(max_iter=10000))]\n",
    "pipe = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_2d_decisionboundary\n",
    "\n",
    "# TODO: Given the best polynomial degree, train your model again, report the test accuracy and plot the decision boundary.\n",
    "#       Here you can use plot_2d_decisionboundary() from utils.py, because plotting the decision boundary with preprocessing is more complicated.\n",
    "#       Instead of calculating the decision boundary exactly, the function uses a grid-based approach, where each (x,y) position in the plot is colored\n",
    "#       according to the prediction of the estimator given (x,y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Report your results. Answer the following questions in full sentences.\n",
    "\n",
    "* What degrees did you try out and why?  \n",
    ">\n",
    "\n",
    "* For what degree does the pipeline perform best?  \n",
    "> \n",
    "\n",
    "* Would this polynomial degree also perform best on another dataset?  \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edHXCg-IzkJg"
   },
   "source": [
    "## 1c) Comparing kNN and Logistic Regression\n",
    "We want you to compare the kNN and the logistic regression classifier. For logistic regression use logistic regression with and without polynomial preprocessing. Use the previous dataset (dataset 5) and dataset 1.\n",
    "\n",
    "**TODO:** Compare the performance of the kNN and Logistic Regression classifiers you trained before. You can skip the hyperparameter tuning and use the best k and polynomial degree from before. Therefor, a simple train-test split is sufficient (e.g. 70:30)\n",
    "- compare the accuracies\n",
    "- it may be useful to plot the decision boundaries for both classifiers (feel free to use plot_2d_decisionboundary() from the code snippet below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "aOIj3_vUzkJh"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the data and the decision boundary of the classifiers. plot_2d_decisionboundary() in utils.py can be used.\n",
    "#       Add more code if helpful for the comparison of the classifiers. Use the datasets dataset_1.npz and dataset_2.npz\n",
    "\n",
    "from utils import plot_classification_dataset # plot the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle  \n",
    "\n",
    "def train(dataset):\n",
    "    \"\"\"\n",
    "    Train kNN & Log.Reg. on a given dataset and plot the dataset as well as the\n",
    "    model's decision boundary\n",
    "    \n",
    "    Params:\n",
    "        dataset: name of the datase\n",
    "    \n",
    "    Examples:\n",
    "        train('dataset_1')\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"dataset_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"dataset_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANBVeSXjzkJn"
   },
   "source": [
    "**TODO:** Describe your results and analyze them: Is one model performing better than the other? Is there a difference in the datasets causing this behavior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "*dataset_1*:  \n",
    "...\n",
    "\n",
    "\n",
    "*dataset_2*:  \n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Model evaluation (10 points)\n",
    "\n",
    "Consider the following scenario: Two groups of students work on this assignment. They both use the function below to generate a train-test split and compare the performance of kNN and Logistic Regression. However both groups achieve different results. The code snippet below shows how they handled the comparison.\n",
    "Fill the TODOs for training and evaluation of kNN and Logistic Regression with the given hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group1:\n",
      "accuracy: \n",
      "accuracy: \n",
      "group2\n",
      "accuracy: \n",
      "accuracy: \n"
     ]
    }
   ],
   "source": [
    "data_set = np.load('dataset_2.npz')\n",
    "X = data_set['X']\n",
    "y = data_set['y']\n",
    "\n",
    "n = X.shape[0]\n",
    "\n",
    "def train_knn(X_train, X_test, y_train, y_test):\n",
    "    # TODO: train a kNN classifier with k=5 and report the test accuracy\n",
    "    print(\"accuracy: \")\n",
    "    \n",
    "def train_logreg(X_train, X_test, y_train, y_test):\n",
    "    # TODO: train a logistic regression pipeline with polynomial preprocessing (deg=2) and report the test accuracy\n",
    "    print(\"accuracy: \")\n",
    "    \n",
    "def group1_eval():\n",
    "    print(\"group1:\")\n",
    "    n_train = int(4*n/5)\n",
    "    X_train = X[:n_train]\n",
    "    X_test = X[n_train:]\n",
    "    y_train = y[:n_train]\n",
    "    y_test = y[n_train:]\n",
    "    \n",
    "    train_knn(X_train, X_test, y_train, y_test)\n",
    "    train_logreg(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    \n",
    "def group2_eval():\n",
    "    print(\"group2\")\n",
    "    n_test = int(n/5)\n",
    "    X_train = X[n_test:]\n",
    "    X_test = X[:n_test]\n",
    "    y_train = y[n_test:]\n",
    "    y_test = y[:n_test]\n",
    "    \n",
    "    train_knn(X_train, X_test, y_train, y_test)\n",
    "    train_logreg(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "group1_eval()\n",
    "group2_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Explain why they achieve different results. Can you think of any better strategy than the simple train-test split to make the results more comparable? Feel free to add some code to underline your points or show your recommended approach.\n",
    "\n",
    "* What do you think, whose results are correct?\n",
    "> \n",
    "* How could they improve their evaluation to be more confident about the results? (hint: If we make a statement like classifier 1 outperforms classifier 2 on this dataset, the statement should be representative for the whole dataset. As always, efficient solutions are preferable!)\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your recommended approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Yet another Dataset (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: * Load dataset_3.npz (data is stored again in X and in y)\n",
    "#       * Train and report the accuracy for the kNN and the logistic regression classifier. Use logistic regression without polynomial preprocessing.\n",
    "#       * You may use a simple train-test split or your proposed strategy from part 2.\n",
    "\n",
    "data_set = np.load('dataset_3.npz')\n",
    "X = data_set['X']\n",
    "y = data_set['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Report the accuracy for each class. To report the accuracy for class i, compute the accuracy score only on samples that belong to class i.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Describe your results and analyze them: Do you observe any problematic behavior?\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: analyze the dataset; focus on possible reasons for above mentioned problems.\n",
    "#       You might consider plotting the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Discuss the properties of the dataset and how they influence the performance of the classifiers.\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Given your results and the properties of the data, reflect on accuracy (over all classes) as a metric. Propose another metric that would be better suited for this kind of dataset and explain why. Adjustments to accuracy are fine, too.\n",
    "\n",
    "> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HCypy1U8zkI0",
    "qxex3z5tzkJR",
    "edHXCg-IzkJg"
   ],
   "name": "Copy of Project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
