\documentclass[a4paper,oneside,12pt]{article}
 
\usepackage[english]{babel}
\usepackage{newtxtext}
\usepackage{substitutefont}

\usepackage{amsbsy, amsmath, amsfonts}
\usepackage{siunitx}
\usepackage{graphicx}

\newcommand{\spr}[1]{\ensuremath{^\textrm{#1}}}
\newcommand{\sub}[1]{\ensuremath{_\textrm{#1}}}

\usepackage{multirow}
\usepackage{booktabs}
\usepackage{float}

\usepackage[]{hyperref}
\usepackage[shortlabels]{enumitem} 

\usepackage{natbib}
\bibliographystyle{alpha}
\setcitestyle{super,open={[},close={]}}

\newcommand{\skipline}{\hfill \break \\}
\newcommand{\rom}[1]{\uppercase\expandafter{\romannumeral #1\relax}}

\usepackage{caption}
\captionsetup[figure]{labelfont=it,textfont=it}
\captionsetup[table]{labelfont=it,textfont=it}
\usepackage{subfig}

\usepackage[strict]{changepage}

\usepackage[left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm,includehead,includefoot,headheight=16pt]{geometry}

\usepackage{fancyhdr}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt} 
\fancyhead[L]{\nouppercase{\leftmark}}
\cfoot{\thepage}
\pagestyle{fancy}


\usepackage{setspace}
\setstretch{1.5}

\usepackage{emptypage}
\usepackage{amsmath}
\usepackage{xfrac}
\usepackage{amssymb}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage{mathdots}
\usepackage[dvipsnames]{xcolor}

\author{Yasmin Bouhlada, Annalisa Dettori, Andrea Schinoppi}
\title{Report third project}
\date{January 2024}

\setcounter{section}{1}
\begin{document}

\makeatletter
    \begin{titlepage}
        \begin{center}
            \includegraphics[width=0.7\linewidth]{Bielefeld_University.png}\\[4ex]
            {\huge \bfseries  \@title }\\[2ex] 
            {\large  \@author}\\[50ex] 
            {\large \@date}
        \end{center}
    \end{titlepage}
\makeatother
\thispagestyle{empty}
\newpage

\section{Introduction}

\section{Data Set}

\subsection{First data set}

The first data set was made of ten columns $X$ for the independent variable and one column for the dependent variable $y$. The data set had $1000$ numeric samples and it has no NaNs. We didn't know what the variables represented, but we could resume the main information of the variables with this table:  

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\empty & $X_1$ & $X_2$ & $X_3$ & $X_4$ & $X_5$ & $X_6$ & $X_7$ & $X_8$ & $X_9$ & $X_{10}$ \\
\hline
mean & $0.66$ & $-0.06$ & $0.02$ & $-0.2$ & $0.04$ & $-0.1$ & $0.12$ & $0.06$ & $0.08$ & $0.06$ \\
\hline
std dev & $2.60$ & $5.80$ & $3.50$ & $5.76$ & $2.69$ & $5.75$ & $5.78$ & $5.90$ & $3.31$ & $5.79$\\
\hline
min & $-7.32$ & $-9.98$ & $-8.44$ & $-9.95$ & $-9.13$ & $-9.98$ & $-9.98$ & $-9.99$ & $-7.91$ & $-9.98$\\
\hline
max & $7.4$ & $9.97$ & $7.43$ & $9.97$ & $8.92$ & $9.98$ & $9.98$ & $9.97$ & $8.26$ & $9.97$\\
\hline

\end{tabular}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
\empty & $y$\\
\hline
mean &  $0.5$\\
\hline
std dev & $0.5$\\
\hline
min &  $0$\\
\hline
max  & $1$\\
\hline

\end{tabular}
\end{table}


\subsection{Second data set}

The first data set was made of thirteen columns $X$ for the independent variable and one column for the dependent variable $y$. The data set had $110$ numeric samples and it has no NaNs. We didn't know what the variables represented, but we could resume the main information of the variables with this table:  

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\empty & $X_1$ & $X_2$ & $X_3$ & $X_4$ & $X_5$ & $X_6$ & $X_7$ & $X_8$ & $X_9$ & $X_{10}$ \\
\hline
mean & $-0.28$ & $-0.33$ & $-0.25$ & $0.02$ & $-0.03$ & $-0.31$ & $-0.48$ & $0.08$ & $-0.19$  & $-0.31$ \\
\hline
std dev & $0.92$ & $0.79$ & $0.99$ & $1.06$ & $1.26$ & $1.13$ & $1.00$ & $1.13$ & $1.15$ & $ 0.8$ \\
\hline
min & $-1.49$ & $-1.23$ & $-3.31$ & $-2.42$ & $-1.95$ & $-2.62$ & $-2.61$ & $-1.84$ & $-2.5$ & $-1.51$ \\
\hline
max & $2.13$ & $2.17$ & $1.79$ & $3.31$ & $4.05$ & $2.44$ & $1.71$ & $2.76$ & $2.84$ & $2.23$ \\
\hline

\end{tabular}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\empty & $X_{11}$ & $X_{12}$ & $X_{13}$ & $y$\\
\hline
mean &  $0.36$ & $-0.39$ & $-0.34$ & $1.82$\\
\hline
std dev &  $0.90$ & $1.16$ & $0.85$ & $0.38$\\
\hline
min &  $-1.6$ & $-2.88$ & $-1.46$ & $1$\\
\hline
max  &  $2.33$ & $2.04$ & $1.96$ & $2$\\
\hline

\end{tabular}
\end{table}

\subsection{Third data set}

The third data set (named \textit{real world data}) was a real data set regarding the prices of some houses. It was made of ten columns $X_1,\;.\;.\;.\;,X_{10}$ for the independent variables and one column for the dependent variable $y$. The data set had $1095$ numeric samples and it had no NaNs.

The labels of the variables were: "\texttt{LotArea}", "\texttt{TotalBsmtSF}", "\texttt{1stFlrSF}", "\texttt{2ndFlrSF}", "\texttt{GrLivArea}", "\texttt{WoodDeckSF}", "\texttt{OpenPorchSF}", "\texttt{3SsnPoarch}", "\texttt{ScreenPorch}" and "\texttt{PoolArea}".

We could resume the main information of the variables with this table:  

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\empty & $X_1$ & $X_2$ & $X_3$ & $X_4$ & $X_5$ & $X_6$ & $X_7$ & $X_8$ & $X_9$ & $X_{10}$ \\
\hline
mean & $10722.41$ & $1159.84$ & $0$ & $338.71$ & $1505.13$ & $91,06$ & $47.26$ & $2.78$ & $15.09$  & $2.14$ \\
\hline
std dev & $11054.40$ & $376.46$ & $34900$ & $432.04$ & $514.24$ & $120.64$ & $66.79$ & $25.18$ & $56.55$ & $35.79$ \\
\hline
min & $1300$ & $0$ & $343$ & $0$ & $334$ & $0$ & $0$ & $0$ & $0$ & $0$ \\
\hline
max & $215245$ & $3206$ & $3228$ & $1872$ & $4676$ & $670$ & $547$ & $407$ & $480$ & $738$ \\
\hline

\end{tabular}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
\empty & $y$\\
\hline
mean &  $179984.82$\\
\hline
std dev & $77610.06$\\
\hline
min &  $34900$\\
\hline
max  & $755000$\\
\hline

\end{tabular}
\end{table}

\section{Foundations}

\subsection{Methods}

\subsubsection{Filter methods, wrapper methods and embedded methods}

For variables selection what we decided to do was to apply three methods: filter methods, wrapper methods and unbedded methods. 

As filter method, we used the \textit{F measure}. SPIEGAZIONE

As wrapper method we used sequential feature selection both forward and backward. SPIEGAZIONE

As embedded method we used Lasso. SPIEGAZIONE

\subsubsection{Random forest classifier}

SPIEGAZIONE

\subsubsection{Naive Bayes classifier}

SPIEGAZIONE

\subsubsection{Logistic regression}

SPIEGAZIONE

\subsubsection{k nearest neighbours}

SPIEGAZIONE

\subsection{Evaluation}

\subsubsection{Filter method}

With the \textit{F measure} we selected the following features 

\begin{itemize}
\item Two features: \texttt{['TotalBsmtSF' 'GrLivArea']} 
\item Six features:  \texttt{['2ndFlrSF' 'OpenPorchSF' 'WoodDeckSF' '1stFlrSF' 'TotalBsmtSF' 'GrLivArea']}
\end{itemize}

that provided the respective results for the $R^2$ on the test set:
\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
numer of features & $R^2$ \\
\hline
2  & $0.22$ \\
\hline
6  & $0.47$ \\
\hline

\end{tabular}
\end{table}


Both with two variables such as with six variables, the $R^2$ seems to be very low, for two variables is even less than $0.5$, so we can assume the models are both not reliable.

\subsubsection{Wrapper method}

With the \textit{forward feature selection} we selected the following features 

\begin{itemize}
\item Two features: \texttt{['TotalBsmtSF' 'GrLivArea']} 
\item Six features:  \texttt{['LotArea' 'TotalBsmtSF' '1stFlrSF' '2ndFlrSF' 'GrLivArea' 'OpenPorchSF']}
\end{itemize}

that provided the respective results for the $R^2$ on the test set:
\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
numer of features & $R^2$ \\
\hline
2  & $0.22$ \\
\hline
6  & $0.46$ \\
\hline

\end{tabular}
\end{table}

As we can see \textit{forward feature selection} chose the same two variables as the \textit{F measure} did, but others for six variables. In any cases these models are not acceptable, because the values for the $R^2$ are too small.

With the \textit{backward feature selection} we selected the following features 

\begin{itemize}
\item Two features: \texttt{['TotalBsmtSF' '2ndFlrSF']} 
\item Six features:  \texttt{['LotArea' 'TotalBsmtSF' '1stFlrSF' '2ndFlrSF' 'OpenPorchSF' '3SsnPorch']}
\end{itemize}

that provided the respective results for the $R^2$ on the test set:
\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
numer of features & $R^2$ \\
\hline
2  & $0.20$ \\
\hline
6  & $0.44$ \\
\hline

\end{tabular}
\end{table}

Now the second variable has change for the \textit{backward feature selection} from the \textit{F measure} method and \textit{forward feature selection}. We can still say that the values of the $R^2$ are still very small.

\subsubsection{Embedded method}

With \textit{Lasso} we selected the following features 

\begin{itemize}
\item Two features: \texttt{['2ndFlrSF' '1stFlrSF']} 
\item Six features:  \texttt{ ['2ndFlrSF' '1stFlrSF' 'TotalBsmtSF' 'WoodDeckSF' 'OpenPorchSF' 'ScreenPorch']}
\end{itemize}

that provided the respective results for the $R^2$ on the test set:
\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
numer of features & $R^2$ \\
\hline
2  & $0.18$ \\
\hline
6  & $0.44$ \\
\hline

\end{tabular}
\end{table}

The variables selected are a little bit different from the previous ones, but as for the other methods, there are no significant emprovements in the values of the $R^2$

\newpage
\section{Bonus task}

eheh

\newpage
\appendix

\section{Appendix}
banana
\end{document}








